---
hide:
  - navigation
---

# Large Language Models Bootcamp

<div class="flex flex-col items-center justify-center dark-bg" markdown>

<div class="subtitle">üöÄ Announcing FSDL Large Language Models Bootcamp  üöÄ</div>

<!--
<div style="align:center; text-align:center; width:50%" markdown>
On **April 21-22** join several hundred **other builders** and learn **best practices** and tools for **creating products with LLMs** from **expert educators** and **industry leaders** at an **in-person bootcamp** in **San Francisco**.
</div>
-->

[Register now](#register){ .md-button .md-button--primary }

</div>

!!! tip "tl;dr"
    <h2>
    On **April 21-22** join several hundred **other builders** and learn **best practices** and tools for **creating products with LLMs** from **expert educators** and **industry leaders** at an **in-person bootcamp** in **San Francisco**.</h2>

# Why

### We are at the cusp of a technology unlock of a magnitude not seen since the early days of the Internet.

Large language models (LLMs) understand text both semantically and syntactically,
fulfilling the promise of an old idea in artificial intelligence and human-computer interaction:
_Natural Language User Interfaces_, or LUIs.

### As with GUIs, LUIs promise to revolutionize how we use and interface with computing systems and become the specialty of a new class of developer.

At the same time that LLMs have made LUIs possible,
the process for developing an application around machine learning models has become easier.

Where once an idea for a useful, delightful, and intelligent technology
would bottleneck on training models from scratch
and then on deployment,
now an MVP based on pretrained models and APIs can be configured and serving users in an hour.

### With a gold rush come shovels and shovel-sellers.
An entirely new ecosystem of tools and tool vendors has formed around LLMs and LUIs.

Even ML veterans are scrambling to orient themselves to the new possible and figure out the most productive new sets of techniques and tools.

### Engineers are asking themselves:

- "Should I be able to code a Transformer from scratch?"
- "What is 'Prompt Engineering'? How legit is it?"
- "What's the deal with linear-time attention mechanisms?"
- "What will my moat be if I‚Äôm relying on OpenAI's model APIs?"
- "Are there open-source alternatives to LLM vendors?"
- "How do software engineering workflows like CI/CD and test-driven design transfer?"
- "How do computer science principles like compositionality, data structures, and recursion transfer?"
- "Jesus H. Christ, how am I supposed to test these things?"
- "Do I need to buy a cluster of server-grade GPUs like NVIDIA A100s?"
- "How can I ensure a seamless UX while still gathering user feedback to support a data flywheel?"

# What

We have put together a state-of-the-art program
based on emerging conventions in the LLM community and the latest research results
to help you answer these questions and make the transition.

!!! question "What do I need to know already?"
    We aim to get anyone with experience programming in Python ready to start building applications that use LLMs.

    Exposure to at least one of machine learning, frontend, or backend is likely to be helpful.

Here are a few of the benefits of attendance:
<div class="md-typeset__scrollwrap">
  <div class="md-typeset__table">
    <table>
    <thead>
      <tr>
        <th></th>
        <th width="45%">Friday (April 21)</th>
        <th width="45%">Saturday (April 22)</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>9 am</td>
        <td>Registration &amp; Breakfast</td>
        <td>Breakfast</td>
      </tr>
      <tr>
        <td>10 am</td>
        <td>
          <strong>üöÄ Launch an LLM App in 1 Hour</strong>
          <ul>
          <li> Walk through a well-documented sample project using LLM APIs and frameworks, traditional and vector databases, and user feedback ingestion
          <li> Use as starter code to save hours of boilerplate effort on your own project
          </ul>
        </td>
                <td>
          <strong>üå≥ Demo Garden</strong>
          <ul>
            <li>Present your project
          </ul>
        </td>

      </tr>
      <tr>
        <td>11 am</td>
        <td>
          <strong>üóø Foundations of Foundation Models</strong>
          <br />
        <ul>
          <li>Learn the core concepts behind transformer architectures, self-supervised learning, and text generation
          <li>Develop clear intuitions for model internals based on the latest work in "reverse engineering" LLMs
        </ul>
        </td>
        <td>
          <strong>ü§∑ UX for LUIs</strong>
          <ul>
            <li>Review of the best AI-powered apps today
            <li>Principles of successful design for AI-powered apps
          </ul>
        </td>
      </tr>
      <tr>
        <td>12 pm</td>
        <td>Lunch and networking</td>
        <td>Lunch and networking</td>
      </tr>
      <tr>
        <td>1 pm</td>
        <td>
          <strong>‚ú® Learn to Spell: Effectively Using LLMs</strong>
          <ul>
            <li>Learn how vendors, like OpenAI, Cohere, and AI21, compare with each other and with open source options like FLAN-T5 and GLM.
            <li>Prompt engineering tips and tricks: few-shot examples, chain-of-thought, formatting
            <li>Context engineering concepts: incorporating local information into LLM context, the wishlist-fulfillment architecture, long-term memory
            <li>Software tools: LangChain, GPTIndex, Everyprompt, dust.tt
          </ul>
        </td>
        <td>
          <strong>üèéÔ∏è Deploying and Learning in Production</strong>
          <ul>
            <li>Deploying on CPUs vs GPUs
            <li>Why "learn in prod" is the new "test in prod"
            <li>How to monitor models, trace chains, and record feedback
            <li>Methods for learning from user data, like reinforcement learning from human feedback (RLHF), and from chains of LLMs, like Constitutional AI
          </ul>
        </td>
      </tr>
      <tr>
        <td>2 pm</td>
        <td>
          <strong>üëÄ Search 2.0</strong>
          <ul>
            <li>How text embeddings enable semantic search everywhere
            <li>Choosing between vector stores, like FAISS, Milvus, Pinecone, Weaviate, and Vespa
            <li>Jointly embedding multiple types of data for multi-modal semantic search
          </ul>
        </td>
        <td>
          <strong>üîÆ Future Directions</strong>
          <ul>
            <li>Lightning tour of things that are surprisingly possible today
            <li>What you should expect to be possible within a couple of years
            <li>What are still hard research problems
          </ul>
        </td>
      </tr>
      <tr>
      <td>3 pm</td>
      <td>Coffee and networking</td>
      <td>Coffee and networking</td>
      </tr>
      <tr>
      <td>4 pm</td>
      <td>
        Hands-On Workshop: <strong>askFSDL Project</strong>
      </td>
      <td>
        <strong>Harrison Chase</strong>: Creator of LangChain
      </td>
      </tr>
      <tr>
      <td>5 pm</td>
      <td>Hands-On Workshop: <strong>askFSDL Project</strong></td>
      <td>Keynote</td>
      </tr>
      </tbody>
    </table>
  </div>
</div>
- **The askFSDL Sample Project**
    - Walk through a well-documented sample project using LLM APIs and frameworks, traditional and vector databases, and user feedback ingestion
    - Use as starter code to save hours of boilerplate effort on your own project

- **Foundations of Foundation Models**
    - Learn the core concepts behind transformer architectures, self-supervised learning, and text generation
    - Develop clear intuitions for model internals based on the latest work in "reverse engineering" LLMs

- **Learn to Spell: Effectively Using LLMs**
    - Learn how vendors, like OpenAI, Cohere, and AI21, compare with each other and with open source options like FLAN-T5 and GLM.
    - Prompt engineering tips and tricks: few-shot examples, chain-of-thought, formatting
    - Context engineering concepts: incorporating local information into LLM context, the wishlist-fulfillment architecture, long-term memory
    - Software tools: LangChain, GPTIndex, Everyprompt, dust.tt

- **Search 2.0**
    - How text embeddings enable semantic search everywhere
    - Choosing between vector stores, like FAISS, Milvus, Pinecone, Weaviate, and Vespa
    - Jointly embedding multiple types of data for multi-modal semantic search

- **Learning in Production**
    - Why "learn in prod" is the new "test in prod"
    - How to monitor models, trace chains, and record feedback
    - Methods for learning from user data, like reinforcement learning from human feedback (RLHF), and from chains of LLMs, like Constitutional AI

# Who

## Who Are We

We are Full Stack Deep Learning.
We're a team of UC Berkeley PhD alumni
with years of industry experience
who are passionate about teaching people how to make deep neural networks work in the real world.

Since 2018, we have taught in-person bootcamps, online multi-week cohorts, and official semester-long courses at top universities.

<img src="/images/august2018.jpg" width="480px">

### Instructor Team

<div style="display:grid;grid-template-columns:47% 47%; row-gap: 2rem; column-gap:5%;">
  <div class="person" markdown>
    <img src="/images/charles.png" class="person--image" height="160px" width="160px" loading="lazy" alt="Photo of Charles Frye">
    <div><strong>Charles Frye</strong> educates people in AI. He has worked in the AI/ML tooling space, including with companies such as Weights & Biases and Gantry, since getting a PhD in Theoretical Neuroscience at UC Berkeley.</div>
  </div>
  <div class="person" markdown>
    <img src="/images/sergey.png" class="person--image" height="160px" width="160px" loading="lazy" alt="Photo of Sergey Karayev">
    <div markdown>
    <strong>Sergey Karayev</strong> builds AI-powered products as Co-founder of Volition. He co-founded Gradescope after getting a PhD in AI at UC Berkeley.
    </div>
  </div>
  <div class="person" markdown>
    <img src="/images/josh.png" class="person--image" height="160px" width="160px" loading="lazy" alt="Photo of Josh Tobin">
    <div markdown>
    <strong>Josh Tobin</strong> builds tooling for AI products as Co-founder and CEO of Gantry. He worked as a Research Scientist at OpenAI and received a PhD in AI at UC Berkeley.
    </div>
  </div>
</div>

### Guest Talks

<div style="display:grid;grid-template-columns:47% 47%; row-gap: 2rem; column-gap:5%;">
  <div class="person" markdown>
    <img src="/images/harrison.jpg" class="person--image" height="160px" width="160px" loading="lazy" alt="Photo of Harrison Chase">
    <div><strong>Harrison Chase</strong> is the creator of LangChain.</div>
  </div>
</div>

## When and Where

The event will be **in-person** and run **all day** on **Friday, April 21, 2023** and **Saturday, April 22, 2023** at the [South San Francisco Conference Center](https://ssfconf.com/).

<iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d74597.27001002253!2d-122.39849142057383!3d37.69637486488224!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x808f79b47d5d81ad%3A0xfd9c1f0af6155a3d!2sSouth%20San%20Francisco%20Conference%20Center!5e0!3m2!1sen!2sus!4v1674094089226!5m2!1sen!2sus" width="600" height="450" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe>

## Sponsors

We're grateful to a number of sponsors who are helping us make this event happen.

### Compute Credit Sponsors

<div style="display:grid;grid-template-columns: 30% 30% 30%; row-gap: 2rem; column-gap:3%;">
  <div class="logo" markdown>
    <img src="/images/modal-logo.jpg" class="person--image" height="160px" width="160px" loading="lazy" alt="Logo of Modal">
    </div>
  <div class="logo" markdown>
    <img src="/images/banana-logo.jpg" height="160px" width="160px" loading="lazy" alt="Logo of banana.dev">
    </div>
  <div class="logo" markdown>
    <img src="/images/lambdalabs-logo.png" height="160px" width="160px" loading="lazy" alt="Logo of LambdaLabs">
    </div>
</div>

### Direct Sponsors

- **Cloud Credits**
    - We're partnering with compute vendors to offer free cloud credits to all attendees, including credits for [Modal](https://modal.com), [banana.dev](https://banana.dev), the [LambdaLabs GPU Cloud](https://lambdalabs.com/cloud) and the [OpenAI API](https://openai.com/api/).

Interested in sponsoring?
You can read more about tiers and benefits [here](./sponsors).
Contact [`sponsorships@fullstackdeeplearning.com`](mailto:sponsorships@fullstackdeeplearning.com) with inquiries.

## Register

**üê£ Early Bird Discount**: until we're half full, tickets are 1/3 off full price.

<div class="flex justify-center">
  <div class="tier">
    <div class="tier--header">Academics</div>
    <div class="tier--price">
      <div><strike>$450</strike> üê£$295</div>
    </div>
    <div style="margin-top: auto">
      <a href="https://fsdl.me/2023-conf-academic" style="width: 100%" class="md-button md-button--primary"> Get discount code </a>
    </div>
  </div>
  <div class="tier">
    <div class="tier--header">Professionals</div>
    <div class="tier--price">
      <div><strike>$1450</strike> üê£$950</div>
    </div>
    <div style="margin-top: auto">
      <a href="https://fsdl.me/2023-conf-irl-reg" style="width: 100%" class="md-button md-button--primary">Register</a>
    </div>
  </div>
</div>
